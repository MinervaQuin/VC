{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "rojo = [0, 0, 255]\n",
    "azul = [255, 0, 0]\n",
    "amarillo = [0, 255, 255]\n",
    "lila = [255, 0, 255]\n",
    "naranja =  [0, 128, 255]\n",
    "verde =  [0, 128, 0]\n",
    "\n",
    "lower_range = np.array([0, 0, 100], dtype=np.uint8)\n",
    "upper_range = np.array([100, 100, 255], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint_emo_color(img_url, color):\n",
    "    img = cv2.imread(img_url)\n",
    "    img_copia = img.copy()\n",
    "    model = YOLO('yolov8n-seg.pt') \n",
    "\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    for result in results:\n",
    "        masks = result.masks.data\n",
    "        boxes = result.boxes.data\n",
    "        # extract classes\n",
    "        clss = boxes[:, 5]\n",
    "        # get indices of results where class is 0 (people in COCO)\n",
    "        people_indices = torch.where(clss == 0)\n",
    "        # use these indices to extract the relevant masks\n",
    "        people_masks = masks[people_indices]\n",
    "        people_boxes = boxes[people_indices]\n",
    "\n",
    "        people_mask = torch.any(people_masks, dim=0).int() * 255\n",
    "        # Resize the mask to match the original image size\n",
    "        print(\"Original Image Shape:\", img_copia.shape)\n",
    "        print(\"Resized Mask Shape:\", people_mask.shape)\n",
    "        people_mask = cv2.resize(people_mask.numpy().astype(np.uint8), (img_copia.shape[1], img_copia.shape[0]))\n",
    "\n",
    "        # Make the mask yellow and transparent\n",
    "        yellow_color = np.array(color)  # Amarillo\n",
    "        img_copia[people_mask > 0] = (img_copia[people_mask > 0] * 0.7 + yellow_color * 0.3).astype(int)\n",
    "        # cv2.imwrite('merged_segs2.jpg', img_copia)\n",
    "        return img_copia\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analizar_y_modificar(img_path, nombre, frame):\n",
    "    # Analizar la imagen para obtener la emoción\n",
    "    result = DeepFace.analyze(img_path=img_path, enforce_detection=False, actions=['emotion'])\n",
    "    \n",
    "    # Imprimir los resultados para entender la estructura\n",
    "    print(result)\n",
    "    \n",
    "    # Obtener la emoción detectada (asumiendo que result es una lista)\n",
    "    emocion_detectada = result[0]['dominant_emotion']\n",
    "\n",
    "    # Cargar la imagen original\n",
    "    imagen = cv2.imread(img_path)\n",
    "    img_copia = imagen.copy()\n",
    "\n",
    "    # Definir un rango de colores para \"angry\" (por ejemplo, rojo)\n",
    "    if emocion_detectada.lower() == 'angry':\n",
    "    \n",
    "        mask = cv2.inRange(imagen, lower_range, upper_range)\n",
    "\n",
    "        # Aplicar la máscara para cambiar el color de la cara a rojo\n",
    "        img_copia = paint_emo_color(img_path, rojo)\n",
    "        img_copia[mask > 0] = rojo  \n",
    "\n",
    "\n",
    "    elif emocion_detectada.lower() == 'happy':\n",
    "        # Crear una máscara para los píxeles en el rango de colores\n",
    "        mask = cv2.inRange(imagen, lower_range, upper_range)\n",
    "        \n",
    "        # Aplicar la máscara para cambiar el color de la cara a rojo\n",
    "        img_copia = paint_emo_color(img_path, amarillo)\n",
    "        img_copia[mask > 0] = amarillo \n",
    "\n",
    "    elif emocion_detectada.lower() == 'sad':\n",
    "        # Crear una máscara para los píxeles en el rango de colores\n",
    "        mask = cv2.inRange(imagen, lower_range, upper_range)\n",
    "        \n",
    "        # Aplicar la máscara para cambiar el color de la cara a rojo\n",
    "        img_copia = paint_emo_color(img_path, azul)\n",
    "        img_copia[mask > 0] = azul \n",
    "\n",
    "    elif emocion_detectada.lower() == 'fear':\n",
    "        # Crear una máscara para los píxeles en el rango de colores\n",
    "        mask = cv2.inRange(imagen, lower_range, upper_range)\n",
    "        \n",
    "        # Aplicar la máscara para cambiar el color de la cara a rojo\n",
    "        img_copia = paint_emo_color(img_path,  lila)\n",
    "        img_copia[mask > 0] =  lila  \n",
    "\n",
    "    elif emocion_detectada.lower() == 'surprise':\n",
    "        # Crear una máscara para los píxeles en el rango de colores\n",
    "        mask = cv2.inRange(imagen, lower_range, upper_range)\n",
    "        \n",
    "        # Aplicar la máscara para cambiar el color de la cara a rojo\n",
    "        img_copia = paint_emo_color(img_path,  naranja)\n",
    "        img_copia[mask > 0] =  naranja  \n",
    "        print(\"surprise\")\n",
    "\n",
    "    elif emocion_detectada.lower() == 'disgust':\n",
    "        # Crear una máscara para los píxeles en el rango de colores\n",
    "        mask = cv2.inRange(imagen, lower_range, upper_range)\n",
    "        \n",
    "        # Aplicar la máscara para cambiar el color de la cara a rojo\n",
    "        img_copia = paint_emo_color(img_path,  verde)\n",
    "        img_copia[mask > 0] =  verde  \n",
    "        print(\"asqueado\")\n",
    "\n",
    "    # Guardar la imagen modificada\n",
    "    cv2.imwrite(nombre + \"_modificado.jpg\", imagen)\n",
    "    height, width, _ = img_copia.shape\n",
    "    \n",
    "    # Calcular nuevas dimensiones manteniendo la proporción\n",
    "    new_width = 400\n",
    "    new_height = int((new_width / width) * height)\n",
    "    \n",
    "    # Mostrar la imagen en una ventana redimensionada\n",
    "    cv2.namedWindow('Imagen Resultante', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Imagen Resultante', new_width, new_height)\n",
    "    cv2.imshow('Imagen Resultante', img_copia)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'emotion': {'angry': 1.1823140789457607, 'disgust': 7.319572300453265e-05, 'fear': 38.410066867474725, 'happy': 0.00048941222491896, 'sad': 60.25357009491742, 'surprise': 0.0013842904906785968, 'neutral': 0.1521070927706118}, 'dominant_emotion': 'sad', 'region': {'x': 73, 'y': 25, 'w': 115, 'h': 115}}]\n",
      "\n",
      "Original Image Shape: (183, 275, 3)\n",
      "Resized Mask Shape: torch.Size([448, 640])\n"
     ]
    }
   ],
   "source": [
    "analizar_y_modificar(\"C:/Users/Raul/Downloads/PR6_Minerva/triste.jpg\", \"nombre_salida\", None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_PR5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
